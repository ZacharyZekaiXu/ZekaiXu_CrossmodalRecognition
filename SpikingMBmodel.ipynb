{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXBWvjjmRnAQQAz315O709",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZacharyZekaiXu/ZekaiXu_CrossmodalRecognition/blob/main/SpikingMBmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "x_wzfObysYEt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fv_ucfXlWof",
        "outputId": "16ca9b6d-755c-4d84-997c-35622b014fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/BeeBRain2_TouchVision\n"
          ]
        }
      ],
      "source": [
        "from google.colab import output, drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "%cd /content/gdrive/MyDrive/BeeBRain2_TouchVision/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBNz_7SOsXce",
        "outputId": "4a23e69a-4950-4aa4-a4a8-9c0bab56555d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=274491 sha256=d5d5a4fd952fe9fc157f92df98be2202a06c6cf554493c287981f9fb422f60be\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.15.tar.gz (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl size=516860 sha256=67a694bb00443f8802c2029a2cae49d3b91276fff4b306efb5e40ae649636fb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/68/4d/1414be5c2c622bad35364e13213180797717b6d4b8923936dc\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=d5dceaa87dc92c67b61aa74f6af91b5af6b98aa17e181a039310f4fb8175630c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import seaborn as sn\n",
        "import scipy.spatial as ss\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, ChebConv, TAGConv\n",
        "from torch_geometric.utils import normalized_cut\n",
        "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)"
      ],
      "metadata": {
        "id": "neC17qYnsXZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "from datetime import date\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import random\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "tH2b3hf-sXSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install brian2\n",
        "from brian2 import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EaGvdxCDhkk",
        "outputId": "2b896f16-98ac-41fb-a2f3-176fd4e50f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: brian2 in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from brian2) (1.21.6)\n",
            "Requirement already satisfied: jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from brian2) (2.11.3)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from brian2) (0.29.32)\n",
            "Requirement already satisfied: sympy>=1.2 in /usr/local/lib/python3.7/dist-packages (from brian2) (1.7.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from brian2) (3.0.9)\n",
            "Requirement already satisfied: setuptools>=24.2 in /usr/local/lib/python3.7/dist-packages (from brian2) (57.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7->brian2) (2.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.2->brian2) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct Graphs for Tactile Data [class: TactileGraph]"
      ],
      "metadata": {
        "id": "W8RNsp4g1LmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TactileGraph(object):\n",
        "\n",
        "    def __init__(self, k=0, useKNN=0, dist_threshold=0): # we won't use kNN or MST there\n",
        "        # 39 taxles in each tactile finger, with coordinates as:\n",
        "        tact_coordinates = np.array([[-6, 0], [-5.3, -3], [-5.3, 3], [-4.6, -7.8], [-4.6, 7.8],\n",
        "                    [-3.5, 0], [-3.05, -5.2], [-3.05, 5.2], [-3.1, -1.75], [-3.1, 1.75], # 10\n",
        "                    [-1.6, -8.9], [-1.75, -3], [-1.6, 8.9], [-1.75, 3], [-1.5, 0],\n",
        "                    [-0.7, -1.3], [-0.7, 1.3], [0, -6], [0, 6],[0, -3.5],\n",
        "                    [0, 0], [0, 3.5], [0.8, -1.3], [0.8, 1.3], [1.6, -8.9],\n",
        "                    [1.6, 8.9], [1.5, 0], [1.75, 3], [1.75, -3], [3.05, -5.2],\n",
        "                    [3.1, 1.75], [3.05, 5.2], [3.1, -1.75], [3.6, 0], [4.6, -7.8], \n",
        "                    [4.6, 7.8], [5.3, -3], [5.3, 3], [6, 0]\n",
        "                    ])\n",
        "        self.pos = tact_coordinates\n",
        "\n",
        "        if k == 0: # use manual way to construct the graph\n",
        "            self.edge_origins = np.array([1, 1, 1, 2, 3, 6, 2, 2, 7, 9, 3, 3, 8, 10, 4, 4, 7, 11,\n",
        "                    5, 5, 8, 13, 6, 6, 6, 9, 10, 15, 7, 7, 12, 18, 8, 8, 14, 19, 9, 9, 12, 16, \n",
        "                    10, 10, 14, 15, 11, 11, 18, 25, 12, 12, 16, 20, 13, 13, 19, 26, \n",
        "                    14, 14, 17, 22, 15, 15, 15, 16, 17, 21, 16, 16, 21, 23, 17, 17, 21, 24, \n",
        "                    18, 18, 18, 20, 25, 30, 19, 19, 19, 22, 26, 32, 20, 20, 23, 29, \n",
        "                    21, 21, 21, 23, 24, 27, 22, 28, 23, 23, 27, 29, 24, 24, 24, 27, 28, 31, \n",
        "                    25, 35, 26, 36, 27, 27, 33, 34, 28, 28, 31, 32, 29, 29, 30, 33, 30, 30, 35, 37,\n",
        "                    31, 31, 34, 38, 32, 32, 36, 38, 33, 33, 34, 37, 34, 39, 37, 39, 38, 39]) - 1 \n",
        "                    # minus 1 since taxel number from 0 \n",
        "            self.edge_ends = np.array([2, 3, 6, 1, 1, 1, 7, 9, 2, 2, 8, 10, 3, 3, 7, 11, 4, 4, \n",
        "                    8, 13, 5, 5, 9, 10, 15, 6, 6, 6, 12, 18, 7, 7, 14, 19, 8, 8, 12, 16, 9, 9, \n",
        "                    14, 15, 10, 10, 18, 25, 11, 11, 16, 20, 12, 12, 19, 26, 13, 13, \n",
        "                    17, 22, 14, 14, 16, 17, 21, 15, 15, 15, 21, 23, 16, 16, 21, 24, 17, 17, \n",
        "                    20, 25, 30, 18, 18, 18, 22, 26, 32, 19, 19, 19, 23, 29, 20, 20,  \n",
        "                    23, 24, 27, 21, 21, 21, 28, 22, 27, 29, 23, 23, 27, 28, 31, 24, 24, 24,\n",
        "                    35, 25, 36, 26, 33, 34, 27, 27, 31, 32, 28, 28, 30, 33, 29, 29, 35, 37, 30, 30, \n",
        "                    34, 38, 31, 31, 36, 38, 32, 32, 34, 37, 33, 33, 39, 34, 39, 37, 39, 38]) - 1\n",
        "\n",
        "\n",
        "    def getEdge(self):\n",
        "        edges = torch.tensor([self.edge_origins, self.edge_ends])\n",
        "        return edges #self.edge_origins, self.edge_ends\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        graph_x = sample\n",
        "        graph_edge_index = torch.tensor([self.edge_origins, self.edge_ends], dtype=torch.long)\n",
        "        graph_pos = self.pos\n",
        "        data = Data(x=graph_x, edge_index = graph_edge_index, pos=graph_pos)\n",
        "#       data = []\n",
        "        return data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"{}\".format(self.__class__.__name__)"
      ],
      "metadata": {
        "id": "sJ7lyDbRsXPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GWGeRUyisXL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Convolution for Tactile Input"
      ],
      "metadata": {
        "id": "Lu51qb-G8BYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresh = 0.5    # neuronal threshold\n",
        "lens = 0.5      # hyper-parameters of approximate function\n",
        "decay = 0.2 \n",
        "\n",
        "# define approximate firing function\n",
        "class ActFun(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.gt(thresh).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        temp = abs(input - thresh) < lens\n",
        "        return grad_input * temp.float()\n",
        "\n",
        "act_fun = ActFun.apply\n",
        "\n",
        "\n",
        "# membrane potential update, for GCN\n",
        "def mem_update_conv(ops, x, edge_idxs, mem, spike):\n",
        "    mem = mem * decay * (1. - spike) + ops(x, edge_idxs)\n",
        "    spike = act_fun(mem) # act_fun : approximation firing function\n",
        "    return mem, spike\n",
        "\n",
        "def mem_update(ops, x, mem, spike):\n",
        "    mem = mem * decay * (1. - spike) + ops(x)\n",
        "    spike = act_fun(mem)\n",
        "    return mem, spike\n",
        "\n",
        "# cnn_layer(in_channels, out_channels)\n",
        "cfg_cnn = [(2, 64), #(64, 128)\n",
        "] \n",
        "\n",
        "# kernel size\n",
        "cfg_s = [39, 39]\n",
        "\n",
        "# fc layer\n",
        "cfg_fc = [128, 256]\n",
        "gamma = 0.2 # dropout coefficient\n",
        "\n",
        "print(cfg_cnn)\n",
        "print(cfg_fc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T2SjCe_sXId",
        "outputId": "a6ea9b77-828b-4979-98f9-6533ee2f080a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: TactileSGNet\n",
            "[(2, 64)]\n",
            "[128, 256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TactileSGNet"
      ],
      "metadata": {
        "id": "K6AOKrGy7lTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TactileSGNet(nn.Module):\n",
        "    def __init__(self, num_classes=36, k=0, device=\"cuda:0\"):\n",
        "        super(TactileSGNet, self).__init__()\n",
        "        in_planes, out_planes = cfg_cnn[0]\n",
        "        self.conv1 = TAGConv(in_planes, out_planes, K=3)\n",
        "\n",
        "        self.fc1 = nn.Linear(cfg_s[-1] * cfg_cnn[-1][1], cfg_fc[0])\n",
        "        self.fc2 = nn.Linear(cfg_fc[0], cfg_fc[1])\n",
        "        self.fc3 = nn.Linear(cfg_fc[1], num_classes)\n",
        "        self.num_classes = num_classes\n",
        "        self.graph = TactileGraph(k)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input, training = True):\n",
        "        data = input.to(self.device)\n",
        "        sizes = data.size()\n",
        "        time_window = sizes[-1]\n",
        "\n",
        "        c1_mem = c1_spike = c1_mem_noise = torch.zeros(cfg_s[0], cfg_cnn[0][1], device=self.device)\n",
        "        h1_mem = h1_spike = h1_sumspike = h1_mem_noise = torch.zeros(cfg_fc[0], device=self.device)\n",
        "        h2_mem = h2_spike = h2_sumspike = h2_mem_noise = torch.zeros(cfg_fc[1], device=self.device)\n",
        "        h3_mem = h3_spike = h3_sumspike = h3_mem_noise = torch.zeros(self.num_classes, device=self.device)\n",
        "        \n",
        "        inputs = data.split(1, dim=len(sizes)-1)\n",
        "        for step in range(time_window): # simulation time steps\n",
        "            x = inputs[step].squeeze()\n",
        "            x = x.to(self.device)\n",
        "            graph_data = self.graph(x)\n",
        "            x = graph_data.x.to(self.device) \n",
        "            edge_idxs = graph_data.edge_index.to(self.device)\n",
        "\n",
        "            c1_mem, c1_spike = mem_update_conv(self.conv1, x, edge_idxs, c1_mem, c1_spike)\n",
        "            x = c1_spike\n",
        "            x = x.view(-1)\n",
        "\n",
        "            h1_mem, h1_spike = mem_update(self.fc1, x, h1_mem, h1_spike)\n",
        "            h1_sumspike += h1_spike\n",
        "            h2_mem, h2_spike = mem_update(self.fc2, h1_spike, h2_mem,h2_spike)\n",
        "            h2_sumspike += h2_spike\n",
        "            h3_mem, h3_spike = mem_update(self.fc3, h2_spike, h3_mem, h3_spike)\n",
        "            h3_sumspike += h3_spike\n",
        "\n",
        "        outputs = h3_sumspike / time_window\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "O-owAazjsXFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training SGCN"
      ],
      "metadata": {
        "id": "D34wGOZABpHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "# model name\n",
        "model_name = '_TactileSGNet_' # tactile \n",
        "\n",
        "\n",
        "# hyperparameter setting\n",
        "num_classes = 36\n",
        "k = 3 # number of nodes to be connected for constructing graph\n",
        "num_run = 1\n",
        "learning_rate = 1e-3 #1e-3\n",
        "num_epochs = 100\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Event-based tactile dataset\n",
        "class tactileDataset(Dataset):\n",
        "    def __init__(self, data_path, train=True):\n",
        "        if train:\n",
        "            self.files = os.listdir(data_path + '/train')\n",
        "            self.file_path = data_path + '/train/'\n",
        "        else:\n",
        "            self.files = os.listdir(data_path + '/test')\n",
        "            self.file_path = data_path + '/test/'\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        fileName = self.files[index]\n",
        "        nameStr = fileName.split('_label_')\n",
        "        label = int(nameStr[-1].split('.')[0])\n",
        "        data = torch.from_numpy(np.load(self.file_path + fileName)) #torch.FloatTensor(np.load(self.file_path + fileName))\n",
        "        label = torch.LongTensor([label])                      \n",
        "        return data, label                                                                                                                 \n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "# Decay learning rate\n",
        "def lr_scheduler(optimizer, epoch, init_lr = 0.01, lr_decay_epoch=30):\n",
        "    if epoch % lr_decay_epoch == 0 and epoch > 1:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = param_group['lr'] * 0.1\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "# Tactile dataset\n",
        "data_path = 'Ev-Objects/'\n",
        "trainDataset = tactileDataset(data_path, train=True)\n",
        "testDataset = tactileDataset(data_path, train=False)\n",
        "\n",
        "# run for num_run times\n",
        "best_acc = torch.zeros(num_run)\n",
        "acc_list = list([])\n",
        "training_loss_list = list([])\n",
        "test_loss_list = list([])\n",
        "net_list = list([])\n",
        "\n",
        "for run in range(num_run):\n",
        "    model = TactileSGNet(num_classes, k, device=device)\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss() #nn.MSELoss(reduction='sum') #nn.BCELoss() \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, amsgrad=True)\n",
        "\n",
        "    acc = torch.zeros(num_epochs)\n",
        "    training_loss = torch.zeros(num_epochs)\n",
        "    test_loss = torch.zeros(num_epochs)\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        running_loss = 0\n",
        "        for trainData, trainLabel in tqdm.tqdm(trainDataset): \n",
        "            model.zero_grad()\n",
        "            optimizer.zero_grad()\n",
        "            trainData = trainData.to(device) \n",
        "            outputs = model(trainData)\n",
        "            labels_ = torch.zeros(1, num_classes).scatter_(1, trainLabel.view(-1, 1), 1)\n",
        "            loss = criterion(outputs.cpu(), labels_) \n",
        "              \n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        training_loss[epoch] = running_loss\n",
        "\n",
        "         # testing\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        optimizer = lr_scheduler(optimizer, epoch, learning_rate, 40)\n",
        "        running_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for testData, testLabel in testDataset:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(testData, False)\n",
        "                labels_ = torch.zeros(1, num_classes).scatter_(1, testLabel.view(-1, 1), 1)\n",
        "                loss = criterion(outputs.cpu(), labels_) \n",
        "                running_loss += loss.item()\n",
        "                _, predicted = outputs.cpu().max(0)\n",
        "                total += float(testLabel.size(0))\n",
        "                correct += float(predicted.eq(testLabel).sum().item())\n",
        "                \n",
        "            test_loss[epoch] = running_loss         \n",
        "\n",
        "            acc[epoch] = 100. * float(correct) / float(total)\n",
        "            if best_acc[run] < acc[epoch]:\n",
        "                best_acc[run] = acc[epoch]\n",
        "\n",
        "        test_loss_list.append(test_loss) \n",
        "        training_loss_list.append(training_loss)\n",
        "\n",
        "        acc_list.append(acc)\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            print('At epoch: %s, training_loss: %f, test_loss: %f, best accuracy: %.3f, time elasped: %.3f' % (epoch + 1, training_loss[epoch], test_loss[epoch], best_acc[run], time.time()-start_time ))\n",
        "            start_time = time.time()\n",
        "             \n",
        "    net_list.append(model.state_dict())\n",
        "    \n",
        "# overall state\n",
        "state = {\n",
        "    'net_list': net_list,\n",
        "    'best_acc': best_acc,\n",
        "    'num_epochs': num_epochs,\n",
        "    'acc_list': acc_list,\n",
        "    'training_loss_list': training_loss_list,\n",
        "    'test_loss_list': test_loss_list,\n",
        "}\n",
        "dateStr = date.today().strftime(\"%Y%m%d\")\n",
        "\n",
        "if not os.path.isdir('log_data'):\n",
        "   os.mkdir('log_data')\n",
        "torch.save(state, './log_data/' + dateStr + model_name + '_objects_' +  str(num_classes) + '_k_' + str(k)  + '.t7')\n",
        "print('Avg acc: %f, std: %f: ' % (torch.mean(state['best_acc']), torch.std(state['best_acc'])))"
      ],
      "metadata": {
        "id": "rlXXXQLCsXA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJP-Rg1CsW9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_PN(CPN, gLPN, ELPN, tau_IaPN, Ee, tau_syn_e, Ei, tau_syn_i, EIa, VtPN, VrPN, tau_ref, bPN):\n",
        "\n",
        "    neuron_eqs = '''\n",
        "    dv/dt = (g_l*(E_l-v) + g_e*(E_e-v) - g_i*(E_i-v) - g_Ia*(E_Ia-v) + I0)/C_m    : volt (unless refractory) # Ia is the spike triggered adaptation\n",
        "    dg_e/dt = -g_e/tau_e  : siemens  # post-synaptic exc. conductance # synapses\n",
        "    dg_i/dt = -g_i/tau_i  : siemens  # post-synaptic inh. conductance\n",
        "    dg_Ia/dt = -g_Ia/tau_Ia : siemens # conductance adaptation 'current'\n",
        "    I0 : amp\n",
        "    '''\n",
        "\n",
        "    neuron_modelPN = dict()\n",
        "    neuron_modelPN['model'] = Equations(neuron_eqs, g_l=gLPN, E_l=ELPN, E_e=Ee, E_i=Ei,E_Ia = EIa, C_m=CPN, tau_e=tau_syn_e, tau_i=tau_syn_i,tau_Ia=tau_IaPN)\n",
        "    neuron_modelPN['threshold'] = 'v > VtPN'\n",
        "    neuron_modelPN['reset'] = '''v = VrPN; g_Ia-=bPN'''\n",
        "    neuron_modelPN['refractory'] = tau_ref\n",
        "\n",
        "    return neuron_modelPN\n",
        "\n",
        "def model_LN(CLN, gLLN, ELLN, tau_IaLN, Ee, tau_syn_e, Ei, tau_syn_i, EIa, VtLN, VrLN, tau_ref, bLN):\n",
        "\n",
        "    neuron_eqs = '''\n",
        "    dv/dt = (g_l*(E_l-v) + g_e*(E_e-v) - g_i*(E_i-v) - g_Ia*(E_Ia-v) + I0)/C_m    : volt (unless refractory) # Ia is the spike triggered adaptation\n",
        "    dg_e/dt = -g_e/tau_e  : siemens  # post-synaptic exc. conductance # synapses\n",
        "    dg_i/dt = -g_i/tau_i  : siemens  # post-synaptic inh. conductance\n",
        "    dg_Ia/dt = -g_Ia/tau_Ia : siemens # conductance adaptation 'current'\n",
        "    I0 : amp\n",
        "    '''\n",
        "\n",
        "    neuron_modelLN = dict()\n",
        "    neuron_modelLN['model'] = Equations(neuron_eqs, g_l=gLLN, E_l=ELLN, E_e=Ee, E_i=Ei, E_Ia=EIa, C_m=CLN, tau_e=tau_syn_e, tau_i=tau_syn_i, tau_Ia=tau_IaLN)\n",
        "    neuron_modelLN['threshold'] = 'v > VtLN'\n",
        "    neuron_modelLN['reset'] = '''v = VrLN; g_Ia-=bLN'''\n",
        "    neuron_modelLN['refractory'] = tau_ref\n",
        "\n",
        "    return neuron_modelLN\n",
        "\n",
        "\n",
        "def model_KC(CKC, gLKC, ELKC, tau_IaKC, Ee, tau_syn_e, Ei, tau_syn_i, EIa, VtKC, VrKC, tau_ref, bKC):\n",
        "\n",
        "    neuron_eqs = '''\n",
        "    dv/dt = (g_l*(E_l-v) + g_e*(E_e-v) - g_i*(E_i-v) - g_Ia*(E_Ia-v) + I0)/C_m    : volt (unless refractory) # Ia is the spike triggered adaptation\n",
        "    dg_e/dt = -g_e/tau_e  : siemens  # post-synaptic exc. conductance # synapses\n",
        "    dg_i/dt = -g_i/tau_i  : siemens  # post-synaptic inh. conductance\n",
        "    dg_Ia/dt = -g_Ia/tau_Ia : siemens # conductance adaptation 'current'\n",
        "    I0 : amp\n",
        "    '''\n",
        "\n",
        "    neuron_modelKC = dict()\n",
        "    neuron_modelKC['model'] = Equations(neuron_eqs, DeltaT=1 * mV, g_l=gLKC, E_l=ELKC, E_e=Ee, E_i=Ei, E_Ia=EIa, C_m=CKC, tau_e=tau_syn_e,tau_i=tau_syn_i, tau_Ia=tau_IaKC)\n",
        "    neuron_modelKC['threshold'] = 'v > VtKC'\n",
        "    neuron_modelKC['reset'] = '''v = VrKC; g_Ia-=bKC'''\n",
        "    neuron_modelKC['refractory'] = tau_ref\n",
        "\n",
        "    return neuron_modelKC\n",
        "\n",
        "\n",
        "\n",
        "def network(params,\n",
        "        input_ng,\n",
        "        neuron_modelORN,\n",
        "        neuron_modelPN,\n",
        "        neuron_modelLN,\n",
        "        neuron_modelKC,\n",
        "        wORNinputORN,\n",
        "        wORNPN,\n",
        "        wORNLN,\n",
        "        wLNPN,\n",
        "        wPNKC,\n",
        "        N_glu,\n",
        "        ORNperGlu,\n",
        "        N_KC,\n",
        "        PNperKC,\n",
        "        V0min,\n",
        "        V0max,\n",
        "        I0_PN = 0*nA,\n",
        "        I0_LN = 0*nA,\n",
        "        I0_KC = 0*nA,\n",
        "        inh_delay=0 * ms):\n",
        "    '''\n",
        "    ## ToDo documentation ##\n",
        "    Connect ORNs to PNs such that ORNperGlu ORNs representing input to one Glu connects to 1 PN\n",
        "    repeat for every Glu, using connect_full. Connects ORNs to LNs in the same way.\n",
        "    '''\n",
        "\n",
        "    #########################     NEURONGROUPS     #########################\n",
        "\n",
        "    NG = dict()\n",
        "\n",
        "    # ORN Input\n",
        "    #n_receptors = ORNperGlu * N_glu\n",
        "\n",
        "    if input_ng is not None:\n",
        "        validInputTypes = (PoissonGroup, Group, SpikeSource)\n",
        "        assert isinstance(input_ng, validInputTypes), \"parameter 'input_ng' must be of type: {}\".format(validInputTypes)\n",
        "        NG['ORNinput'] = input_ng\n",
        "\n",
        "    neuron_params_orn = get_args_from_dict(neuron_modelORN, params)\n",
        "    neuron_params_pn = get_args_from_dict(neuron_modelPN, params)\n",
        "    neuron_params_ln = get_args_from_dict(neuron_modelLN, params)\n",
        "    neuron_params_kc = get_args_from_dict(neuron_modelKC, params)\n",
        "\n",
        "    NG['ORN'] = NeuronGroup(N_glu*ORNperGlu, **neuron_modelORN(**neuron_params_orn), namespace=params, method='euler', name='ORNs')\n",
        "    NG['ORN'].I0 = I0_PN\n",
        "    NG['PN'] = NeuronGroup(N_glu, **neuron_modelPN(**neuron_params_pn), namespace=params, method='euler', name='PNs')\n",
        "    NG['PN'].I0=I0_PN\n",
        "    NG['LN'] = NeuronGroup(N_glu, **neuron_modelLN(**neuron_params_ln), namespace=params, method='euler', name='LNs')\n",
        "    NG['LN'].I0=I0_LN\n",
        "    NG['KC'] = NeuronGroup(N_KC, **neuron_modelKC(**neuron_params_kc), namespace=params, method='euler', name='KCs')\n",
        "    NG['KC'].I0=I0_KC\n",
        "\n",
        "    #########################     CONNECTIONS       #########################\n",
        "    c = dict()\n",
        "\n",
        "    if input_ng is not None:\n",
        "        ### input-ORN ###\n",
        "        c['ORNinputORN'] = Synapses(NG['ORNinput'], NG['ORN'], 'w : siemens', on_pre='g_e+=w', namespace=params)\n",
        "        for i in np.arange(len(NG['ORN'])):\n",
        "            #c['ORNinputORN'].connect(i=list(range(i * orn_input_multiplier, (i + 1) * orn_input_multiplier)), j=i)\n",
        "            c['ORNinputORN'].connect(i=i, j=i)\n",
        "            c['ORNinputORN'].w = wORNinputORN\n",
        "\n",
        "    ### ORN-PN ###\n",
        "    c['ORNPN'] = Synapses(NG['ORN'], NG['PN'], 'w : siemens', on_pre='g_e += w', namespace=params)\n",
        "    for i in np.arange(N_glu):\n",
        "        c['ORNPN'].connect(i=list(range(i * ORNperGlu, (i + 1) * ORNperGlu)), j=i)\n",
        "        c['ORNPN'].w = wORNPN\n",
        "\n",
        "    ### ORN-LN ###\n",
        "    c['ORNLN'] = Synapses(NG['ORN'], NG['LN'], 'w : siemens', on_pre='g_e += w', namespace=params)\n",
        "    for i in np.arange(N_glu):\n",
        "        c['ORNLN'].connect(i=list(range(i * ORNperGlu, (i + 1) * ORNperGlu)), j=i)\n",
        "        c['ORNLN'].w = wORNLN\n",
        "\n",
        "    ### LN-PN ###\n",
        "    c['LNPN'] = Synapses(NG['LN'], NG['PN'], 'w : siemens', on_pre='g_i -= w', delay=inh_delay, namespace=params)\n",
        "    c['LNPN'].connect()  # connect_all\n",
        "    c['LNPN'].w = wLNPN\n",
        "\n",
        "\n",
        "    ## PN-KC ##\n",
        "    c['KC'] = Synapses(NG['PN'], NG['KC'], 'w : siemens', on_pre='g_e += w', namespace=params)\n",
        "    c['KC'].connect(p=PNperKC / float(N_glu))\n",
        "    c['KC'].w = wPNKC\n",
        "        # the total number of possible synapses is N_pre*N_post\n",
        "        # when the connection probability is 0.05 then N_syn = N_pre*N_post*0.05 (on average)\n",
        "        # every postsynaptic neuron will receive N_syn/N_post synaptic inputs _on average_\n",
        "        # and every presynaptic input will send out N_syn/N_pre _on average_\n",
        "        # number of inputs per KC is given by the biominal distribution\n",
        "\n",
        "    #########################     INITIAL VALUES     #########################\n",
        "    #NG['PN'].v = np.random.rand(len(NG['PN']))*(V0max-V0min)+V0min\n",
        "    #NG['LN'].v = np.random.rand(len(NG['LN']))*(V0max-V0min)+V0min\n",
        "    #NG['KC'].v = np.random.rand(len(NG['KC']))*(V0max-V0min)+V0min\n",
        "\n",
        "    NG['ORN'].v = np.random.uniform(V0min, V0max, size=len(NG['ORN'])) * volt\n",
        "    NG['PN'].v = np.random.uniform(V0min, V0max, size=len(NG['PN'])) * volt\n",
        "    NG['LN'].v = np.random.uniform(V0min, V0max, size=len(NG['LN'])) * volt\n",
        "    NG['KC'].v = np.random.uniform(V0min, V0max, size=len(NG['KC'])) * volt\n",
        "\n",
        "    return NG, c"
      ],
      "metadata": {
        "id": "_rFkP1DosW6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UN7gAYwTsW17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "poogi-49sWY-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}